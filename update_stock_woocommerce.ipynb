{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyr2bnirR3Tv"
   },
   "source": [
    "# Updating stock in Woocommerce from Edisoft with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python script is designed to update the stock in a web store using the WooCommerce REST API. The script takes stock data from a program called Edisoft and compares it with the stock data in the web store. If there are any differences, the script updates the stock in the web store.\n",
    "\n",
    "Let's go through the script step by step:\n",
    "\n",
    "1. The necessary libraries are imported, including pandas, numpy, re, woocommerce, smtplib, and others.\n",
    "\n",
    "2. Parameter values are set, including the location of the stock files, email parameters, and WooCommerce parameters.\n",
    "\n",
    "3. The script defines a function called **`enviar_email`** which is responsible for sending an email using SMTP with the given information.\n",
    "\n",
    "4. A decorator function called **`log_exception`** is defined. This decorator logs any exceptions raised by a given function and sends an email with the error message.\n",
    "\n",
    "5. The **`file_clean`** function is defined to eliminate rows that are not inventory lines in a file. It uses a regular expression pattern to filter out non-inventory lines.\n",
    "\n",
    "6. The **`select_inventory`** function is defined to select the most recent file starting with \"I20\" within a specified folder. It compares the most recent file with the second most recent file and continues if there is a difference.\n",
    "\n",
    "7. The **`import_clean_inventory`** function is defined to import and clean an Edisoft inventory dataset. It reads the dataset file, extracts information from columns based on fixed positions, converts stock and price columns to appropriate data types, removes duplicates based on ISBN, and returns the cleaned dataset as a pandas DataFrame.\n",
    "\n",
    "8. The **`import_inventary_web`** function is defined to import the inventory from a WooCommerce webshop using the WooCommerce REST API. It creates a WooCommerce API object, downloads products from the webshop, transforms them into a DataFrame, removes duplicates based on product ID, and returns the imported inventory as a DataFrame.\n",
    "\n",
    "9. The **`web_edisoft_join`** function is defined to select items with different stock between the web store inventory and the Edisoft inventory. It joins the two DataFrames based on SKU and ISBN columns, identifies the items with different stock, and returns a filtered DataFrame.\n",
    "\n",
    "10. The **`stock_update_batch`** function is defined to update the stock of the web store using the WooCommerce REST API and verify the update. It creates a WooCommerce API object, divides the inventory DataFrame into batches to avoid exceeding the connection time, updates the stock using the API, and checks if the updated items have been properly updated.\n",
    "\n",
    "11. The script calls the functions in the following sequence:\n",
    "   a. **`import_clean_inventory`** function to import and clean the Edisoft inventory dataset.\n",
    "   b. **`import_inventary_web`** function to import the inventory from the web store.\n",
    "   c. **`web_edisoft_join`** function to select items with different stock between the web store and Edisoft inventories.\n",
    "   d. **`stock_update_batch`** function to update the stock in the web store.\n",
    "\n",
    "Overall, this script automates the process of updating the stock in a web store by comparing it with the stock data from Edisoft and using the WooCommerce REST API to make the necessary updates. It also handles exceptions and sends email notifications in case of errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfcU554TSJXz"
   },
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jVRLZkrrbOD3",
    "outputId": "18efbe4c-f585-408e-ecb7-d802eff35734"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: WooCommerce in c:\\users\\luis\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: requests in c:\\users\\luis\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from WooCommerce) (2.26.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\luis\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->WooCommerce) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\luis\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->WooCommerce) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\luis\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->WooCommerce) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\luis\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->WooCommerce) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install WooCommerce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "3NRJJePxRxrW"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "from woocommerce import API\n",
    "import filecmp\n",
    "from datetime import date\n",
    "import csv\n",
    "import smtplib\n",
    "from email.message import EmailMessage\n",
    "from functools import wraps\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WKhqqw6Vzk7"
   },
   "source": [
    "## Parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "43LMxSpkV-pF"
   },
   "outputs": [],
   "source": [
    "# location where the stock files are located\n",
    "path = \"W:/soft/exporsinli/\"\n",
    "# email parameters\n",
    "sender = \"yourmaailsender@xxx.com\"\n",
    "recipient = \"yourmaailrecipient@xxx.com\"\n",
    "mail_pass = \"yourpassword\"\n",
    "smtp_server = \"yoursmtpserver\"\n",
    "bcc = \"youremailbcc.xxx.com\"\n",
    "# woocommerce parameters\n",
    "url = \"https://yourwebsiteurl.com\"\n",
    "consumer_key = \"ck_*****\"\n",
    "consumer_secret = \"cs_*****\"\n",
    "timeout = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MLa1864cSZ5L"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNjjQWPIXuVq"
   },
   "source": [
    "### enviar_email()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMbEvQMEScwS"
   },
   "source": [
    "This function **`enviar_email()`** sends an email using the Simple Mail Transfer Protocol (SMTP). It takes the following arguments:\n",
    "\n",
    "* **`info`** (str): Information about the email.\n",
    "* **`sender`** (str): Sender's email address.\n",
    "* **`recipient`** (str): Recipient's email address.\n",
    "* **`smtp_server`** (str): SMTP server address.\n",
    "* **`mail_pass`** (str): Sender's email password.\n",
    "* **`bcc`** (str, optional): Email address for BCC (blind carbon copy) recipient. Defaults to None.\n",
    "\n",
    "The function constructs an email message using the EmailMessage class from the email.message module. It sets the From, To, Subject, and Content of the email based on the provided information.\n",
    "\n",
    "The subject line of the email is generated dynamically by including the current date using the date.today() function from the datetime module.\n",
    "\n",
    "The body of the email includes a formatted message with the current date, indicating the completion of a program for updating stock on a website, and the provided info string.\n",
    "\n",
    "The function attempts to send the email by establishing a secure connection to the SMTP server using the smtplib.SMTP_SSL class. It logs in with the sender's email address and password and sends the constructed message using the send_message method of the mail_server object.\n",
    "\n",
    "If there is an exception during the email sending process, it catches the smtplib.SMTPException, prints an error message, and returns False.\n",
    "\n",
    "The function returns True if the email is sent successfully.\n",
    "\n",
    "This function provides a convenient way for data scientists to send emails using SMTP with customizable sender, recipient, server, and password. It simplifies the process of constructing and sending email messages, making it easier to incorporate email notifications into data science workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g9ZEw6ipUrvh"
   },
   "source": [
    "The function **`enviar_email()`** sends an email using the Simple Mail Transfer Protocol (SMTP). It takes the following arguments:\n",
    "\n",
    "- **`info`** (str): Information about the email.\n",
    "- **`sender`** (str): Sender's email address.\n",
    "- **`recipient`** (str): Recipient's email address.\n",
    "- **`smtp_server`** (str): SMTP server address.\n",
    "- **`mail_pass`** (str): Sender's email password.\n",
    "- **`bcc`** (str, optional): Email address for BCC (blind carbon copy) recipient. Defaults to None.\n",
    "\n",
    "The function constructs an email message using the **`EmailMessage`** class from the **`email.message`** module. It sets the **`From`**, **`To`**, **`Subject`**, and **`Content`** of the email based on the provided information.\n",
    "\n",
    "The subject line of the email is generated dynamically by including the current date using the **`date.today()`** function from the **`datetime`** module.\n",
    "\n",
    "The body of the email includes a formatted message with the current date, indicating the completion of a program for updating stock on a website, and the provided **`info`** string.\n",
    "\n",
    "The function attempts to send the email by establishing a secure connection to the SMTP server using the **`smtplib.SMTP_SSL`** class. It logs in with the sender's email address and password and sends the constructed message using the **`send_message`** method of the **`mail_server`** object.\n",
    "\n",
    "If there is an exception during the email sending process, it catches the **`smtplib.SMTPException`**, prints an error message, and returns **`False`**.\n",
    "\n",
    "The function returns **`True`** if the email is sent successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "q-X5L8xfSc_q"
   },
   "outputs": [],
   "source": [
    "def enviar_email(info,\n",
    "                 sender=sender,\n",
    "                 recipient=recipient,\n",
    "                 smtp_server=smtp_server,\n",
    "                 mail_pass=mail_pass,\n",
    "                 bcc=None):\n",
    "    \"\"\"\n",
    "    Sends an email using SMTP with the given information.\n",
    "\n",
    "    Args:\n",
    "        info (str): Information about the email.\n",
    "        sender (str): Sender's email address.\n",
    "        recipient (str): Recipient's email address.\n",
    "        smtp_server (str): SMTP server address.\n",
    "        mail_pass (str): Sender's email password.\n",
    "        bcc (str, optional): Email address for BCC recipient. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the email is sent successfully, False otherwise.\n",
    "    \"\"\"\n",
    "    message = EmailMessage()\n",
    "    message[\"From\"] = sender\n",
    "    message[\"To\"] = recipient\n",
    "    if bcc:\n",
    "        message[\"Bcc\"] = bcc\n",
    "    message[\"Subject\"] = f\"stock update {date.today()}\"\n",
    "    body = f\"\"\"The execution of the program to update the stock on the website\n",
    "    on {date.today()} has finished.\n",
    "\n",
    "    The result has been:\n",
    "\n",
    "    {info}\n",
    "    \"\"\"\n",
    "    message.set_content(body)\n",
    "\n",
    "    try:\n",
    "        with smtplib.SMTP_SSL(smtp_server) as mail_server:\n",
    "            mail_server.set_debuglevel(1)\n",
    "            mail_server.login(sender, mail_pass)\n",
    "            mail_server.send_message(message)\n",
    "    except smtplib.SMTPException as e:\n",
    "        print(\"An error occurred while sending the email:\", e)\n",
    "        return False\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BkLZ92klYkyH"
   },
   "source": [
    "### log_exception()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fA27SoLMY2Tv"
   },
   "source": [
    "The **`log_exception`** function is a decorator that can be applied to other functions in order to log any exceptions that occur during their execution. It performs the following steps:\n",
    "\n",
    "1. Decorator Setup: The **`@wraps(func)`** decorator ensures that the wrapper function maintains the same name and documentation as the original function being decorated.\n",
    "\n",
    "2. Wrapper Function: The **`wrapper`** function is defined within the**`log_exception`** function. This function serves as a wrapper around the decorated function.\n",
    "\n",
    "3. Exception Handling: Inside the **`wrapper`** function, a **`try-except`** block is used to catch any exceptions that may occur during the execution of the decorated function (**`func`**). If an exception is raised, it will be caught in the **`except`** block.\n",
    "\n",
    "4. Logging: If an exception is caught, the function proceeds to log the error message in a CSV file. The **`log_file`** variable stores the name of the CSV file (\"log_update_stock.csv\"). The **`error_message`** variable is created, which includes the details of the error message and the name of the function where the exception occurred. The error message is appended to the CSV file using the **`csv.writer`** object.\n",
    "\n",
    "5. Email Notification: After logging the exception, the **`enviar_email`** function is called to send an email with the error message. The **`error_message`** is passed as an argument to the **`enviar_email`** function.\n",
    "\n",
    "6. Return: The **`wrapper`** function returns the result of the decorated function (**`func(*args, **kwargs)`**). If no exception occurs, the function execution continues as normal.\n",
    "\n",
    "By using the **`log_exception`** decorator on a function, any exceptions that occur during the execution of that function will be caught, logged to a CSV file, and an email notification will be sent. This helps in tracking and analyzing the errors that occur during the execution of the decorated function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "aB_YHZmcZQKO"
   },
   "outputs": [],
   "source": [
    "def log_exception(func):\n",
    "    \"\"\"\n",
    "    A decorator function that logs exceptions raised by a given function.\n",
    "\n",
    "    Args:\n",
    "        func (callable): The function to be decorated.\n",
    "\n",
    "    Returns:\n",
    "        callable: The decorated function.\n",
    "\n",
    "    Raises:\n",
    "        None.\n",
    "\n",
    "    Examples:\n",
    "        >>> @log_exception\n",
    "        ... def my_function():\n",
    "        ...     # code goes here\n",
    "        ...\n",
    "        >>> my_function()\n",
    "        # If an exception is raised, it will be logged and an email will be sent.\n",
    "\n",
    "    \"\"\"\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            log_file = \"log_update_stock.csv\"\n",
    "            error_message = f\"The following error occurred: {e} in the function\\\n",
    "                             {func.__name__}\\n\"\n",
    "            with open(log_file, \"a\", encoding=\"utf-8\", newline='') as csv_file:\n",
    "                csv_writer = csv.writer(csv_file)\n",
    "                csv_writer.writerow([date.today(), error_message.strip()])\n",
    "            enviar_email(error_message)\n",
    "            exit()\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6022clTfrI1E"
   },
   "source": [
    "### file_clean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4uXI266rJaZ"
   },
   "source": [
    "The **`file_clean`** function takes a file path as input and modifies the file by removing rows that are not considered inventory lines.\n",
    "\n",
    "Inside the function, a regular expression pattern **`^D[0-9]`** is defined, which matches lines starting with 'D' followed by a digit. This pattern is used to identify inventory lines.\n",
    "\n",
    "The file is opened in read mode using **`open(file_path, 'r')`**, and the lines are read using the **`readlines()`** method. Then, the file is opened in write mode using **`open(file_path, 'w')`** to overwrite its contents.\n",
    "\n",
    "A list comprehension is used to filter out non-inventory lines from the **`lines`** list. Only the lines that match the pattern are included in the **`inventory_lines`** list.\n",
    "\n",
    "Finally, the **`writelines()`** method is used to write the **`inventory_lines`** back to the file, effectively removing the non-inventory lines.\n",
    "\n",
    "The function does not return any value (**`None`**) but modifies the file directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "efDY8laJrJpB"
   },
   "outputs": [],
   "source": [
    "@log_exception\n",
    "def file_clean(file_path):\n",
    "    \"\"\"\n",
    "    Void function for eliminating rows that are not inventory lines.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path of the file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Raises:\n",
    "        None\n",
    "\n",
    "    Examples:\n",
    "        >>> file_clean('inventory.txt')\n",
    "        # The function will modify the 'inventory.txt' file,\n",
    "        # removing non-inventory lines.\n",
    "\n",
    "    \"\"\"\n",
    "    pattern = '^D[0-9]'\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    with open(file_path, 'w') as file:\n",
    "        inventory_lines = [line for line in lines if re.match(pattern, line)]\n",
    "        file.writelines(inventory_lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5VFINPbamiJ"
   },
   "source": [
    "### select_inventory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLt8eomxamty"
   },
   "source": [
    "The**`select_inventory`** function takes a**`path`** argument as input, representing the folder to search for files. It selects the most recent file starting with \"I20\" within the folder, compares it with the second most recent file, and returns the filename of the most recent file if there is a difference.\n",
    "\n",
    "The function starts by initializing an empty**`file_list`** to store the filenames that start with \"I20\". It iterates over the files in the specified**`path`** using**`os.listdir(path)`** and checks if each filename starts with \"I20\". If a match is found, the full file path is created using**`os.path.join(path, filename)`** and added to the**`file_list`.\n",
    "\n",
    "The**`file_list`** is then sorted based on the creation time of the files, with the most recent file appearing first. The filenames are sorted in descending order using the**`reverse=True`** parameter.\n",
    "\n",
    "The most recent and second most recent filenames are extracted from the sorted**`file_list`. The function then proceeds to print the names of the files.\n",
    "\n",
    "The**`file_clean`** function is called to clean both the most recent and second most recent files by eliminating rows that are not inventory lines.\n",
    "\n",
    "Next, the function compares the content of the two files using**`filecmp.cmp(edisoft_today, edisoft_previous)`. If the files are identical, it prints a message, logs the update in the \"log_update_stock.csv\" file, sends an email, and exits the script.\n",
    "\n",
    "Finally, if there are differences between the files or if the comparison step was skipped, the filename of the most recent file (`edisoft_today`) is returned.\n",
    "\n",
    "Note: Ensure that you have implemented the**`file_clean`** function and have the necessary code to send emails (`env\n",
    "\n",
    "iar_email`) and handle the logging of updates in the \"log_update_stock.csv\" file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "vXxd5s_Zam9g"
   },
   "outputs": [],
   "source": [
    "@log_exception\n",
    "def select_inventory(path):\n",
    "    \"\"\"\n",
    "    Selects the most recent file starting with \"I20\" within the specified folder.\n",
    "    If there is a difference with the second most recent file, the function\n",
    "    continues.\n",
    "\n",
    "    Args:\n",
    "        path (str): The path of the folder to search for files.\n",
    "\n",
    "    Returns:\n",
    "        str: The filename of the most recent file.\n",
    "\n",
    "    Raises:\n",
    "        None\n",
    "\n",
    "    Examples:\n",
    "        >>> select_inventory('/path/to/folder')\n",
    "        # The function will locate the most recent \"I20\" file within the folder,\n",
    "        # compare it with the second most recent file,\n",
    "        # and return the filename of the most recent file if there is\n",
    "        # a difference.\n",
    "\n",
    "    \"\"\"\n",
    "    file_list = []\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.startswith(\"I20\"):\n",
    "            path_file = os.path.join(path, filename)\n",
    "            file_list.append(path_file)\n",
    "\n",
    "    file_list = sorted(file_list, key=os.path.getctime, reverse=True)\n",
    "    edisoft_today = file_list[0]\n",
    "    edisoft_previous = file_list[1]\n",
    "\n",
    "    print(f\"Today's file name is {edisoft_today} and yesterday's file name\\\n",
    "            is {edisoft_previous}.\")\n",
    "\n",
    "    # Clean files\n",
    "    file_clean(edisoft_today)\n",
    "    file_clean(edisoft_previous)\n",
    "\n",
    "    # Check for changes between the last two edisoft stock files\n",
    "    if filecmp.cmp(edisoft_today, edisoft_previous):\n",
    "        print(\"No update due to no changes - select_inventory\")\n",
    "        with open(\"log_update_stock.csv\", \"a\", encoding=\"utf-8\",\n",
    "                  newline='') as csv_file:\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "            csv_writer.writerow([date.today(), \"No update due to no changes -\\\n",
    "                                                select_inventory\"])\n",
    "        enviar_email(\"No update due to no changes - select_inventory\")\n",
    "        exit()\n",
    "\n",
    "    return edisoft_today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zO0Bls4dfxsh"
   },
   "source": [
    "### import_clean_inventory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OEbxKeffx3G"
   },
   "source": [
    "\n",
    "The **`import_clean_inventory`** function takes a **`path`** argument representing the path of the dataset file. It imports and cleans the edisoft inventory dataset with fixed position columns.\n",
    "\n",
    "The function begins by calling the **`select_inventory`** function to get the most recent file in the specified path.\n",
    "\n",
    "Then, the edisoft inventory dataset is read using **`pd.read_csv(edisoft_today, encoding=\"latin-1\")`. The dataset is printed and displayed.\n",
    "\n",
    "The script proceeds to extract information in columns based on fixed positions. Columns **`isbn`**, **`stock`**, and **`price`** are created using string slicing on the first column of the dataset.\n",
    "\n",
    "Next, the script removes dashes from the **`isbn`** column and drops the original column using **`str.replace(\"-\", \"\")`** and **`drop()`** methods, respectively.\n",
    "\n",
    "The **`stock`** column is converted to integer type using **`.astype(int)`**, and the **`price`** column is converted to float type by dividing it by 1000 after converting it to integer type.\n",
    "\n",
    "The cleaned dataset is printed and displayed.\n",
    "\n",
    "Duplicates in the **`isbn`** column are checked by finding duplicated values. If duplicates exist,\n",
    "\n",
    " they are printed and displayed. The duplicates are then removed from the dataset using **`drop_duplicates()`**.\n",
    "\n",
    "After cleaning, the function prints the dataset's information using **`info()`** method.\n",
    "\n",
    "Finally, the cleaned dataset is returned as a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "_mQGYR20fyHz"
   },
   "outputs": [],
   "source": [
    "@log_exception\n",
    "def import_clean_inventory(path):\n",
    "    \"\"\"\n",
    "    Imports and cleans an edisoft inventory dataset with fixed position columns.\n",
    "\n",
    "    Args:\n",
    "        path (str): The path of the dataset file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned edisoft inventory dataset.\n",
    "\n",
    "    Raises:\n",
    "        None\n",
    "\n",
    "    Examples:\n",
    "        >>> import_clean_inventory('/path/to/dataset.csv')\n",
    "        # The function will import the dataset, clean it by extracting columns with fixed positions,\n",
    "        # convert stock and price columns to appropriate data types, remove duplicates based on ISBN,\n",
    "        # and return the cleaned dataset as a DataFrame.\n",
    "\n",
    "    \"\"\"\n",
    "    edisoft_today = select_inventory(path)\n",
    "\n",
    "    # Import the edisoft inventory dataset\n",
    "    edisoft_df = pd.read_csv(edisoft_today, encoding=\"latin-1\")\n",
    "    print(\"Let's take a look:\\n\", edisoft_df)\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    # Extract information in columns based on fixed positions\n",
    "    edisoft_df['isbn'] = edisoft_df.iloc[:, 0].str[1:18]\n",
    "    edisoft_df['stock'] = edisoft_df.iloc[:, 0].str[18:25]\n",
    "    edisoft_df['price'] = edisoft_df.iloc[:, 0].str[-10:-1]\n",
    "\n",
    "    # Remove dashes and delete the original column\n",
    "    edisoft_df['isbn'] = edisoft_df[\"isbn\"].str.replace(\"-\", \"\")\n",
    "    edisoft_df.drop(edisoft_df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "    # Convert stock from text to int and price from text to float\n",
    "    edisoft_df[\"stock\"] = edisoft_df[\"stock\"].astype(int)\n",
    "    edisoft_df[\"price\"] = edisoft_df[\"price\"].astype(int) / 1000\n",
    "\n",
    "    print(\"Let's take another look:\\n\", edisoft_df)\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    # Check for duplicates based on ISBN\n",
    "    duplicates = edisoft_df[edisoft_df[\"isbn\"].duplicated()]\n",
    "    if not duplicates.empty:\n",
    "        print(\"Tenemos duplicados:\\n\", duplicates.sort_values(\"isbn\"))\n",
    "        edisoft_df.drop_duplicates(subset=\"isbn\", inplace=True)\n",
    "        duplicates_after_cleaning = edisoft_df[edisoft_df[\"isbn\"].duplicated()]\n",
    "        print(\"We have duplicates after cleaning:\\n\", duplicates_after_cleaning.sort_values(\"isbn\"))\n",
    "\n",
    "    print(\"Let's look at the type of data we have:\\n\", edisoft_df.info())\n",
    "    return edisoft_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJnxYVvApu1A"
   },
   "source": [
    "### import_inventory_web()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qng5rvaGpvBM"
   },
   "source": [
    "This script is used to import the inventory from a WooCommerce webshop using the WooCommerce REST API. Let's go through the script step by step:\n",
    "\n",
    "1. The function **`import_inventory_web`** is defined with four parameters: **`url`, **`consumer_key`**, **`consumer_secret`**, and **`timeout`**. These parameters are used to establish a connection with the WooCommerce webshop and retrieve the inventory data.\n",
    "\n",
    "2. The function has a docstring that provides information about the purpose of the function, its arguments, return value, and examples of how to use it.\n",
    "\n",
    "3. The script starts by creating an API object (**`wcapi`**) using the provided URL, consumer key, consumer secret, and timeout values. This object allows interaction with the WooCommerce REST API.\n",
    "\n",
    "4. Products are downloaded from the webshop in batches of 100 products per page. The script initializes an empty dictionary (`pags_products`) to store the product data from each page. It then enters a while loop to fetch products from each page incrementally.\n",
    "\n",
    "5. Inside the loop, the script makes a GET request to the WooCommerce API endpoint for retrieving products. The **`params`** argument is used to specify the number of products per page (**`per_page`**) and the current page number (**`page`**). The response is stored in the **`response`** variable.\n",
    "\n",
    "6. The response is converted to JSON format using the **`json()`** method, and the resulting JSON data is stored in the **`products`** variable.\n",
    "\n",
    "7. If there are no more products in the response (i.e., **`products`** is empty), the loop is exited.\n",
    "\n",
    "8. The script then normalizes the product JSON data into a pandas DataFrame (`df`) using **`pd.json_normalize(products)`**.\n",
    "\n",
    "9. The DataFrame for the current page is added to the **`pags_products`** dictionary with a key representing the page number.\n",
    "\n",
    "10. The page number is incremented by 1 for the next iteration of the loop.\n",
    "\n",
    "11. After all pages have been processed, the script concatenates all the DataFrames in **`pags_products`** into a single DataFrame (**`web_all_df`**) using **`pd.concat`**.\n",
    "\n",
    "12. From the combined DataFrame, only specific columns (**`id`**, **`sku`, **`name`, **`stock_quantity`) are selected and stored in the **`web_df`** DataFrame.\n",
    "\n",
    "13. The script prints the downloaded inventory data (**`web_df`**) and a line of dashes for visual separation.\n",
    "\n",
    "14. Duplicate products based on the **`id`** column are searched for in **`web_df`**, and any duplicates found are removed using the **`drop_duplicates`** method.\n",
    "\n",
    "15. The script prints whether duplicates are present in the cleaned **`web_df`** DataFrame.\n",
    "\n",
    "16. Finally, the function returns the imported inventory as a pandas DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "x3NylzsBpvPL"
   },
   "outputs": [],
   "source": [
    "@log_exception\n",
    "def import_inventary_web(url=url,\n",
    "                         consumer_key=consumer_key,\n",
    "                         consumer_secret=consumer_secret,\n",
    "                         timeout=timeout):\n",
    "    \"\"\"\n",
    "    Imports the inventory from a WooCommerce webshop using the WooCommerce REST API.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the WooCommerce webshop.\n",
    "        consumer_key (str): The consumer key for the REST API authentication.\n",
    "        consumer_secret (str): The consumer secret for the REST API authentication.\n",
    "        timeout (int): The request timeout in seconds.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The imported inventory as a pandas DataFrame.\n",
    "\n",
    "    Raises:\n",
    "        None\n",
    "\n",
    "    Examples:\n",
    "        >>> import_inventory_web('https://yoursiteweb.com', 'ck_****',\n",
    "        >>>     'cs_****', 500)\n",
    "        # The function will create a WooCommerce API object, download products from the webshop,\n",
    "        # transform them into a DataFrame, remove duplicates based on product ID, and return the\n",
    "        # imported inventory as a DataFrame.\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"We start with the function import_inventory_web\")\n",
    "    # Create the API object\n",
    "    wcapi = API(url=url,\n",
    "                consumer_key=consumer_key,\n",
    "                consumer_secret=consumer_secret,\n",
    "                timeout=timeout)\n",
    "    print(\"Created wcapi\")\n",
    "\n",
    "    # Download products from the webshop\n",
    "    pags_products = {}\n",
    "    page = 1\n",
    "    while True:\n",
    "        print(f\"Let's go for page {page} in the while loop\")\n",
    "        response = wcapi.get('products', params={'per_page': 100, 'page': page})\n",
    "        print(\"Created response\")\n",
    "        products = response.json()\n",
    "        print(\"Created products\")\n",
    "        if not products:  # No more products\n",
    "            break\n",
    "        df = pd.json_normalize(products)\n",
    "        pags_products[\"page_\" + str(page)] = df\n",
    "        page += 1\n",
    "\n",
    "    # Combine dataframes from the dictionary\n",
    "    web_all_df = pd.concat(pags_products.values(), ignore_index=True)\n",
    "    # Select the fields of interest\n",
    "    web_df = web_all_df[['id', 'sku', 'name', 'stock_quantity']]\n",
    "    print(\"Let's take a look at the data downloaded from the website\\n\", web_df)\n",
    "    print(\"-\"*100)\n",
    "\n",
    "    # Search for and remove duplicates based on product ID\n",
    "    web_df.drop_duplicates(subset=['id'], inplace=True)\n",
    "    print(\"We have duplicates on the web after deleting them?\\n\",\n",
    "            web_df[web_df.duplicated(subset=['id'])].sort_values(\"id\"))\n",
    "    return web_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M884_heqWoKW"
   },
   "source": [
    "### web_edisoft_join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJnbk_I2WoVJ"
   },
   "source": [
    "The function **web_edisoft_join`** is designed to compare the stock data between two dataframes: **`web_df`** representing the stock data from a web page and **`edisoft_df`** representing the stock data from a management program called Edisoft. The function performs the following steps:\n",
    "\n",
    "1. Joins the two dataframes based on the columns 'sku' in **`web_df`** and 'isbn' in **`edisoft_df`**. The resulting dataframe is stored in **`web_edisoft`**.\n",
    "\n",
    "2. Prints the merged data (**`web_edisoft`**) to display the joined information.\n",
    "\n",
    "3. Checks for missing values (**`NaN`**) in the merged dataframe and prints the count of NaN values for each column.\n",
    "\n",
    "4. Fills the missing stock values (**`NaN`**) in the 'stock' column of **`web_edisoft`** with the corresponding values from the 'stock_quantity' column.\n",
    "\n",
    "5. Adds a new column called 'to_save' to mark the books that have different stock quantities in both dataframes. If the 'stock_quantity' is different from the 'stock', the value in 'to_save' is set to 1; otherwise, it is set to 0.\n",
    "\n",
    "6. Filters out the books with different stock quantities by selecting rows where the 'to_save' column is equal to 1.\n",
    "\n",
    "7. Keeps only the 'id' and 'stock' columns in the resulting dataframe (**`web_edisoft`**) and renames the 'stock' column to 'stock_quantity'.\n",
    "\n",
    "8. Converts the 'stock_quantity' column to the 'int32' data type.\n",
    "\n",
    "9. Converts all values in the dataframe to strings using the **`astype('str')`** method.\n",
    "\n",
    "10. Prints the books that need to be updated based on the differences in stock quantities, along with the number of books to be updated.\n",
    "\n",
    "11. If no books require an update, a message is printed, and the current date and a corresponding message are written to a CSV file called \"log_update_stock.csv\". An email is also sent, assuming the necessary function **`enviar_email`** is defined elsewhere. The program then exits.\n",
    "\n",
    "12. The function prints the information of the resulting dataframe (**`web_edisoft`**) using the **`info()`** method.\n",
    "\n",
    "13. Finally, the function returns the resulting dataframe.\n",
    "\n",
    "The function aims to identify and select the items that have different stock quantities between the web page and Edisoft, providing a filtered dataframe with the items that require updating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "9rloykPuWokm"
   },
   "outputs": [],
   "source": [
    "@log_exception\n",
    "def web_edisoft_join(web_df, edisoft_df):\n",
    "    \"\"\"\n",
    "    Selects the items with different stock between two dataframes: one containing stock data from a web page and the\n",
    "    other from a management program called Edisoft.\n",
    "\n",
    "    Args:\n",
    "        web_df (pd.DataFrame): DataFrame with stock data from the web page.\n",
    "        edisoft_df (pd.DataFrame): DataFrame with stock data from Edisoft.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with the items that have different stock in both dataframes.\n",
    "\n",
    "    Raises:\n",
    "        None\n",
    "\n",
    "    Examples:\n",
    "        >>> web_edisoft_join(web_df, edisoft_df)\n",
    "        # The function will join the two dataframes based on the 'sku' and 'isbn' columns,\n",
    "        # identify the items with different stock, and return a filtered dataframe.\n",
    "\n",
    "    \"\"\"\n",
    "    # Join the datasets using 'sku' and 'isbn' as keys\n",
    "    web_edisoft = web_df.set_index('sku').join(edisoft_df.set_index('isbn'), lsuffix='_web', rsuffix='_edisoft')\n",
    "\n",
    "    print(\"Let's see the merged data:\\n\", web_edisoft)\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    # Check for missing values after merging\n",
    "    print(f\"We have {web_edisoft.isna().sum().sum()} NaN values after merging\\n\")\n",
    "    print(web_edisoft.isna().sum())\n",
    "\n",
    "    # Fill missing stock values with the web stock_quantity\n",
    "    web_edisoft['stock'] = web_edisoft['stock'].fillna(web_edisoft['stock_quantity'])\n",
    "    print(web_edisoft['stock_quantity'].isna().sum())\n",
    "\n",
    "    # Mark the books that have different stock in both dataframes\n",
    "    web_edisoft['to_save'] = np.where(web_edisoft['stock_quantity'] != web_edisoft['stock'], 1, 0)\n",
    "\n",
    "    # Filter out the books with different stock\n",
    "    web_edisoft = web_edisoft[web_edisoft['to_save'] == 1]\n",
    "\n",
    "    # Keep only the 'id' and 'stock' columns\n",
    "    web_edisoft = web_edisoft[['id', 'stock']]\n",
    "    web_edisoft.rename(columns={'stock': 'stock_quantity'}, inplace=True)\n",
    "\n",
    "    # Convert stock_quantity to int\n",
    "    web_edisoft['stock_quantity'] = web_edisoft['stock_quantity'].astype('int32')\n",
    "\n",
    "    # Convert all values to strings\n",
    "    web_edisoft = web_edisoft.astype('str')\n",
    "\n",
    "    print(\"Let's take a look at the books to be updated:\\n\", web_edisoft)\n",
    "    print(f\"The number of books to be updated is: {web_edisoft.shape[0]}\")\n",
    "\n",
    "    if web_edisoft.shape[0] == 0:\n",
    "        print(\"No update when Edisoft inventory matches web inventory\")\n",
    "        with open(\"log_update_stock.csv\", \"a\", encoding=\"utf-8\", newline='') as csv_file:\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "            csv_writer.writerow([date.today(), \"No update when Edisoft inventory matches web inventory\"])\n",
    "            enviar_email(\"No update when Edisoft inventory matches web inventory\")\n",
    "        exit()\n",
    "\n",
    "    print(web_edisoft.info())\n",
    "    return web_edisoft\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gq_F_LYe7GbM"
   },
   "source": [
    "### stock_update_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fii7yD-T7Gk8"
   },
   "source": [
    "The function **`stock_update_batch`** is responsible for updating the stock of a web store using the WooCommerce REST API and verifying if the update has been performed correctly. Here's a breakdown of what the function does:\n",
    "\n",
    "1. It takes several parameters: **`df`** (a Pandas DataFrame containing the stock data to be updated), **`url`** (the URL of the WooCommerce web store), **`consumer_key`** and **`consumer_secret`** (authentication credentials for the REST API), and **`timeout`** (the request timeout in seconds).\n",
    "\n",
    "2. An API object (**`wcapi`**) is created using the provided URL, consumer key, consumer secret, and timeout.\n",
    "\n",
    "3. The function converts the DataFrame (**`df`**) into a dictionary (**`df_dict`**). It then randomly selects a sample of items from the dictionary for checking the update.\n",
    "\n",
    "4. The DataFrame is split into batches to avoid exceeding the connection time. Each batch is used to create a dictionary (**`stock_to_update`**) that is passed to the WooCommerce API's **`put`** method, which updates the stock of the web store.\n",
    "\n",
    "5. After the update, the function checks if the updated items have been properly updated. It retrieves the product information from the API using the product IDs from the randomly selected items. The retrieved information is converted into a DataFrame (**`product_df`**), and the stock quantity is compared with the expected stock quantity from **`df_dict`**. If a mismatch is found, an error message is printed, and the item is recorded in a log file.\n",
    "\n",
    "6. Finally, the function writes a summary of the update to the log file and sends an email notification.\n",
    "\n",
    "Please note that there are a few missing parts in the code, such as the definition of the **`API`** class and the **`enviar_email`** function, which are referenced but not provided in the code. You will need to ensure that these parts are correctly defined and imported for the script to work as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "N01xTrfz93Di"
   },
   "outputs": [],
   "source": [
    "@log_exception\n",
    "def stock_update_batch(df,\n",
    "                       url=url,\n",
    "                       consumer_key=consumer_key,\n",
    "                       consumer_secret=consumer_secret,\n",
    "                       timeout=timeout):\n",
    "    \"\"\"\n",
    "    Updates the stock of a web store using the WooCommerce REST API and verifies the update.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the stock data to be updated.\n",
    "        url (str): The URL of the WooCommerce web store.\n",
    "        consumer_key (str): The consumer key for the REST API authentication.\n",
    "        consumer_secret (str): The consumer secret for the REST API authentication.\n",
    "        timeout (int): The request timeout in seconds.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Raises:\n",
    "        None\n",
    "\n",
    "    Examples:\n",
    "        >>> stock_update_batch(df, url, consumer_key, consumer_secret, timeout)\n",
    "        # The function will update the stock of the web store using the provided DataFrame,\n",
    "        # and then it will check if the update has been performed correctly.\n",
    "\n",
    "    \"\"\"\n",
    "    # Create the API object\n",
    "    wcapi = API(url=url,\n",
    "                consumer_key=consumer_key,\n",
    "                consumer_secret=consumer_secret,\n",
    "                timeout=timeout)\n",
    "\n",
    "    # Create a dictionary from the DataFrame and select a random sample for checking\n",
    "    df_dict = df.to_dict('records')\n",
    "    number_items_to_check = math.ceil(len(df_dict) * 5 / 100)\n",
    "    items_to_check = sample(range(len(df_dict)), number_items_to_check)\n",
    "\n",
    "    # Divide the DataFrame into batches to avoid exceeding the connection time\n",
    "    interval_for_cut = math.ceil(df.shape[0] / 10)\n",
    "    for df_to_update in np.array_split(df, interval_for_cut):\n",
    "        # Create a dictionary to pass to wcapi for updating the stock\n",
    "        stock_to_update = {'update': df_to_update.to_dict('records')}\n",
    "        wcapi.put(\"products/batch\", stock_to_update).json()\n",
    "\n",
    "    # Check if the updated items have been properly updated\n",
    "    id_list = [df_dict[i]['id'] for i in items_to_check]\n",
    "    stock_list = [df_dict[i]['stock_quantity'] for i in items_to_check]\n",
    "    id_stock = zip(id_list, stock_list)\n",
    "\n",
    "    for item, stock_item in id_stock:\n",
    "        product = wcapi.get(\"products/\" + str(item)).json()\n",
    "        product_df = pd.json_normalize(product)\n",
    "        product_df = product_df.loc[:, ('id', 'sku', 'name', 'stock_quantity')]\n",
    "        stock_prod = product_df['stock_quantity'].item()\n",
    "\n",
    "        if stock_prod != int(stock_item):\n",
    "            print(f\"At least the following item has not been updated: {item}\")\n",
    "            with open(\"log_update_stock.csv\", \"a\", encoding=\"utf-8\", newline='') as csv_file:\n",
    "                csv_writer = csv.writer(csv_file)\n",
    "                csv_writer.writerow([date.today(), f\"At least the following item has not been updated: {item}\"])\n",
    "                enviar_email(f\"At least the following item has not been updated: {item}\")\n",
    "            exit()\n",
    "\n",
    "    with open(\"log_update_stock.csv\", \"a\", encoding=\"utf-8\", newline='') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow([date.today(), f\"The number of books that have been updated is: {df.shape[0]}\"])\n",
    "        enviar_email(f\"The number of books that have been updated is: {df.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jCxE2oSh5qBY",
    "outputId": "ee2dca19-9e27-4d4b-c9b3-2678f184e1b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's file name is W:/soft/exporsinli/I203996 and yesterday's file name            is W:/soft/exporsinli/I203953.\n",
      "Let's take a look:\n",
      "       D978-84-16941-15-5000502 000100962\n",
      "0     D978-84-16941-16-2000520 000100962\n",
      "1     D978-84-16941-17-9000681 000100962\n",
      "2     D978-84-16941-18-6000198 000120192\n",
      "3     D978-84-16941-19-3000452 000134615\n",
      "4     D978-84-16941-20-9000536 000134615\n",
      "...                                  ...\n",
      "1525  D978-84-7869-608-6000048 000143750\n",
      "1526  D978-84-7869-611-6000656 000095673\n",
      "1527  D978-84-7869-011-4000012 000187500\n",
      "1528  D978-84-7869-544-7000551 000120192\n",
      "1529  D978-84-7869-612-3000313 000120192\n",
      "\n",
      "[1530 rows x 1 columns]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Let's take another look:\n",
      "                isbn  stock   price\n",
      "0     9788416941162    520  10.096\n",
      "1     9788416941179    681  10.096\n",
      "2     9788416941186    198  12.019\n",
      "3     9788416941193    452  13.461\n",
      "4     9788416941209    536  13.461\n",
      "...             ...    ...     ...\n",
      "1525  9788478696086     48  14.375\n",
      "1526  9788478696116    656   9.567\n",
      "1527  9788478690114     12  18.750\n",
      "1528  9788478695447    551  12.019\n",
      "1529  9788478696123    313  12.019\n",
      "\n",
      "[1530 rows x 3 columns]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Tenemos duplicados:\n",
      "                isbn  stock   price\n",
      "1299  9788478690008      0   0.960\n",
      "1422  9788478692415      0  11.538\n",
      "We have duplicates after cleaning:\n",
      " Empty DataFrame\n",
      "Columns: [isbn, stock, price]\n",
      "Index: []\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1528 entries, 0 to 1529\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   isbn    1528 non-null   object \n",
      " 1   stock   1528 non-null   int32  \n",
      " 2   price   1528 non-null   float64\n",
      "dtypes: float64(1), int32(1), object(1)\n",
      "memory usage: 41.8+ KB\n",
      "Let's look at the type of data we have:\n",
      " None\n",
      "We start with the function import_inventory_web\n",
      "Created wcapi\n",
      "Let's go for page 1 in the while loop\n",
      "Created response\n",
      "Created products\n",
      "Let's go for page 2 in the while loop\n",
      "Created response\n",
      "Created products\n",
      "Let's go for page 3 in the while loop\n",
      "Created response\n",
      "Created products\n",
      "Let's go for page 4 in the while loop\n",
      "Created response\n",
      "Created products\n",
      "Let's go for page 5 in the while loop\n",
      "Created response\n",
      "Created products\n",
      "Let's go for page 6 in the while loop\n",
      "Created response\n",
      "Created products\n",
      "Let's go for page 7 in the while loop\n",
      "Created response\n",
      "Created products\n",
      "Let's go for page 8 in the while loop\n",
      "Created response\n",
      "Created products\n",
      "Let's go for page 9 in the while loop\n",
      "Created response\n",
      "Created products\n",
      "Let's go for page 10 in the while loop\n",
      "Created response\n",
      "Created products\n",
      "Let's go for page 11 in the while loop\n",
      "Created response\n",
      "Created products\n",
      "Let's go for page 12 in the while loop\n",
      "Created response\n",
      "Created products\n",
      "Let's go for page 13 in the while loop\n",
      "Created response\n",
      "Created products\n",
      "Let's go for page 14 in the while loop\n",
      "Created response\n",
      "Created products\n",
      "Let's go for page 15 in the while loop\n",
      "Created response\n",
      "Created products\n",
      "Let's go for page 16 in the while loop\n",
      "Created response\n",
      "Created products\n",
      "Let's go for page 17 in the while loop\n",
      "Created response\n",
      "Created products\n",
      "Let's go for page 18 in the while loop\n",
      "Created response\n",
      "Created products\n",
      "Let's take a look at the data downloaded from the website\n",
      "           id             sku  \\\n",
      "0     110840  vivencias-eval   \n",
      "1     110828       pipe-eval   \n",
      "2     110778         ac-eval   \n",
      "3     110672   9788418044892   \n",
      "4     110669   9788418044847   \n",
      "...      ...             ...   \n",
      "1630   36902   9788478693887   \n",
      "1631   36878   9788478691869   \n",
      "1632   36890   9788478693870   \n",
      "1633   36866   9788478691852   \n",
      "1634   36854   9788478691821   \n",
      "\n",
      "                                                   name  stock_quantity  \n",
      "0     Método de lecto-escritura Vivencias. Evaluació...            9999  \n",
      "1     Método de lecto-escritura PIPE. Evaluación tem...            9997  \n",
      "2     Adaptaciones Curriculares y material complemen...            9999  \n",
      "3     Aprendiz de dragón. Un cuento sobre la resilie...               0  \n",
      "4     Bía, la ciempiés que solo tenía tres. Un cuent...               0  \n",
      "...                                                 ...             ...  \n",
      "1630                 Leco 07 - Leo, Escribo y Comprendo             247  \n",
      "1631                 Leco 05 - Leo, Escribo y Comprendo              21  \n",
      "1632                 Leco 06 - Leo, Escribo y Comprendo              73  \n",
      "1633                 Leco 04 - Leo, Escribo y Comprendo              76  \n",
      "1634                 Leco 01 - Leo. Escribo y Comprendo             185  \n",
      "\n",
      "[1635 rows x 4 columns]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "We have duplicates on the web after deleting them?\n",
      " Empty DataFrame\n",
      "Columns: [id, sku, name, stock_quantity]\n",
      "Index: []\n",
      "Let's see the merged data:\n",
      "                     id                                               name  \\\n",
      "sku                                                                         \n",
      "vivencias-eval  110840  Método de lecto-escritura Vivencias. Evaluació...   \n",
      "pipe-eval       110828  Método de lecto-escritura PIPE. Evaluación tem...   \n",
      "ac-eval         110778  Adaptaciones Curriculares y material complemen...   \n",
      "9788418044892   110672  Aprendiz de dragón. Un cuento sobre la resilie...   \n",
      "9788418044847   110669  Bía, la ciempiés que solo tenía tres. Un cuent...   \n",
      "...                ...                                                ...   \n",
      "9788478693887    36902                 Leco 07 - Leo, Escribo y Comprendo   \n",
      "9788478691869    36878                 Leco 05 - Leo, Escribo y Comprendo   \n",
      "9788478693870    36890                 Leco 06 - Leo, Escribo y Comprendo   \n",
      "9788478691852    36866                 Leco 04 - Leo, Escribo y Comprendo   \n",
      "9788478691821    36854                 Leco 01 - Leo. Escribo y Comprendo   \n",
      "\n",
      "                stock_quantity  stock  price  \n",
      "sku                                           \n",
      "vivencias-eval            9999    NaN    NaN  \n",
      "pipe-eval                 9997    NaN    NaN  \n",
      "ac-eval                   9999    NaN    NaN  \n",
      "9788418044892                0    NaN    NaN  \n",
      "9788418044847                0    NaN    NaN  \n",
      "...                        ...    ...    ...  \n",
      "9788478693887              247  247.0  9.134  \n",
      "9788478691869               21   20.0  9.134  \n",
      "9788478693870               73   71.0  9.134  \n",
      "9788478691852               76   75.0  9.134  \n",
      "9788478691821              185  185.0  9.615  \n",
      "\n",
      "[1621 rows x 5 columns]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "We have 424 NaN values after merging\n",
      "\n",
      "id                  0\n",
      "name                0\n",
      "stock_quantity      0\n",
      "stock             212\n",
      "price             212\n",
      "dtype: int64\n",
      "0\n",
      "Let's take a look at the books to be updated:\n",
      "                    id stock_quantity\n",
      "sku                                 \n",
      "9788416941285  110644            690\n",
      "9789874890221  110062              1\n",
      "9788416941667  108251            944\n",
      "9788461148073  107731            102\n",
      "9788418044991  107537            973\n",
      "...               ...            ...\n",
      "9788478694198   37082           1478\n",
      "9788478690671   37009            474\n",
      "9788478691869   36878             20\n",
      "9788478693870   36890             71\n",
      "9788478691852   36866             75\n",
      "\n",
      "[340 rows x 2 columns]\n",
      "The number of books to be updated is: 340\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 340 entries, 9788416941285 to 9788478691852\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   id              340 non-null    object\n",
      " 1   stock_quantity  340 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 8.0+ KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LUIS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n",
      "send: 'ehlo [192.168.1.34]\\r\\n'\n",
      "reply: b'250-plum.premium.hostns.io Hello 136.red-81-43-69.staticip.rima-tde.net [81.43.69.136]\\r\\n'\n",
      "reply: b'250-SIZE 52428800\\r\\n'\n",
      "reply: b'250-8BITMIME\\r\\n'\n",
      "reply: b'250-PIPELINING\\r\\n'\n",
      "reply: b'250-PIPECONNECT\\r\\n'\n",
      "reply: b'250-AUTH PLAIN LOGIN\\r\\n'\n",
      "reply: b'250 HELP\\r\\n'\n",
      "reply: retcode (250); Msg: b'plum.premium.hostns.io Hello 136.red-81-43-69.staticip.rima-tde.net [81.43.69.136]\\nSIZE 52428800\\n8BITMIME\\nPIPELINING\\nPIPECONNECT\\nAUTH PLAIN LOGIN\\nHELP'\n",
      "send: 'AUTH PLAIN AGx1aXNiYWxsZXN0ZXJvc0BlZGl0b3JpYWxjZXBlLmVzAFNpc2lmbyoyNzAx\\r\\n'\n",
      "reply: b'235 Authentication succeeded\\r\\n'\n",
      "reply: retcode (235); Msg: b'Authentication succeeded'\n",
      "send: 'mail FROM:<luisballesteros@editorialcepe.es> size=399\\r\\n'\n",
      "reply: b'250 OK\\r\\n'\n",
      "reply: retcode (250); Msg: b'OK'\n",
      "send: 'rcpt TO:<luisballesteros@editorialcepe.es>\\r\\n'\n",
      "reply: b'250 Accepted\\r\\n'\n",
      "reply: retcode (250); Msg: b'Accepted'\n",
      "send: 'data\\r\\n'\n",
      "reply: b'354 Enter message, ending with \".\" on a line by itself\\r\\n'\n",
      "reply: retcode (354); Msg: b'Enter message, ending with \".\" on a line by itself'\n",
      "data: (354, b'Enter message, ending with \".\" on a line by itself')\n",
      "send: b'From: luisballesteros@editorialcepe.es\\r\\nTo: luisballesteros@editorialcepe.es\\r\\nSubject: stock update 2023-07-07\\r\\nContent-Type: text/plain; charset=\"utf-8\"\\r\\nContent-Transfer-Encoding: 7bit\\r\\nMIME-Version: 1.0\\r\\n\\r\\nThe execution of the program to update the stock on the website\\r\\n    on 2023-07-07 has finished.\\r\\n\\r\\n    The result has been:\\r\\n\\r\\n    The number of books that have been updated is: 340\\r\\n    \\r\\n.\\r\\n'\n",
      "reply: b'250 OK id=1qHfFv-005CBy-39\\r\\n'\n",
      "reply: retcode (250); Msg: b'OK id=1qHfFv-005CBy-39'\n",
      "data: (250, b'OK id=1qHfFv-005CBy-39')\n",
      "send: 'QUIT\\r\\n'\n",
      "reply: b'221 plum.premium.hostns.io closing connection\\r\\n'\n",
      "reply: retcode (221); Msg: b'plum.premium.hostns.io closing connection'\n"
     ]
    }
   ],
   "source": [
    "edisoft_df = import_clean_inventory(path)\n",
    "web_df = import_inventary_web()\n",
    "web_edisoft = web_edisoft_join(web_df, edisoft_df)\n",
    "stock_update_batch(df = web_edisoft)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
